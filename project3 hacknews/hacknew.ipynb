{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hacker Nesw post Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hacker News is a site started by the startup incubator Y Combinator, where user-submitted stories (known as \"posts\") receive votes and comments, similar to reddit. Hacker News is extremely popular in technology and startup circles, and posts that make it to the top of the Hacker News listings can get hundreds of thousands of visitors as a result.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can find the data set [here](https://www.kaggle.com/hacker-news/hacker-news-posts),but note that I have reducede from almost 300,000 row to 20,000 rows by removing a;; submissions that dide't receive any comments and then randomlu sampling from the remaining submissions.Below are descriptions of the [columns](https://www.kaggle.com/hacker-news/hacker-news-posts)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- id: the unique identifier from Hacker News for the post\n",
    "- title: the title of the post\n",
    "- url: the URL that the posts links to, if the post has a URL\n",
    "- num_points: the number of points the post acquired, calculated as the total number of upvotes minus the total number of downvotes\n",
    "- num_comments: the number of comments on the post\n",
    "- author: the username of the person who submitted the post\n",
    "- created_at: the date and time of the post's submission"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This analysis will\n",
    "- Determine if *Ask HN* or *Show HN* recevice more comments \n",
    "- Determine if posts at certain time would received mote comments on average\n",
    "\n",
    "Users use *Ask HN* posts to ask the Hacker News community a specific. Some exmaples of *Ask HN* posts are,\n",
    "\n",
    "* Ask HN: How to improve my personal website?\n",
    "* Ask HN: Am I the only one outraged by Twitter shutting down share counts?\n",
    "* Ask HN: Aby recent changes to CSS that broke mobile?\n",
    "\n",
    "Users use *Show HN* posts to show the Hacker News community a project, product or something interesting. Some exmaples of *Show HN* posts are,\n",
    "* Show HN: Wio Link  ESP8266 Based Web of Things Hardware Development Platform'\n",
    "* Show HN: Something pointless I made\n",
    "* Show HN: Shanhu.io, a programming playground powered by e8vm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['id', 'title', 'url', 'num_points', 'num_comments', 'author', 'created_at'],\n",
       " ['12224879',\n",
       "  'Interactive Dynamic Video',\n",
       "  'http://www.interactivedynamicvideo.com/',\n",
       "  '386',\n",
       "  '52',\n",
       "  'ne0phyte',\n",
       "  '8/4/2016 11:52'],\n",
       " ['10975351',\n",
       "  'How to Use Open Source and Shut the Fuck Up at the Same Time',\n",
       "  'http://hueniverse.com/2016/01/26/how-to-use-open-source-and-shut-the-fuck-up-at-the-same-time/',\n",
       "  '39',\n",
       "  '10',\n",
       "  'josep2',\n",
       "  '1/26/2016 19:30'],\n",
       " ['11964716',\n",
       "  \"Florida DJs May Face Felony for April Fools' Water Joke\",\n",
       "  'http://www.thewire.com/entertainment/2013/04/florida-djs-april-fools-water-joke/63798/',\n",
       "  '2',\n",
       "  '1',\n",
       "  'vezycash',\n",
       "  '6/23/2016 22:20'],\n",
       " ['11919867',\n",
       "  'Technology ventures: From Idea to Enterprise',\n",
       "  'https://www.amazon.com/Technology-Ventures-Enterprise-Thomas-Byers/dp/0073523429',\n",
       "  '3',\n",
       "  '1',\n",
       "  'hswarna',\n",
       "  '6/17/2016 0:01']]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# read the hacker New files\n",
    "from csv import reader\n",
    "opened_file = open('hacker_news.csv')\n",
    "read_file = reader(opened_file)\n",
    "hn = list(read_file)\n",
    "\n",
    "# show the 1st 5 rows\n",
    "\n",
    "hn[0:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since the header row of the dataset is the column names, it is not needed for the analysis and will be removed into a seprarte lust"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['id', 'title', 'url', 'num_points', 'num_comments', 'author', 'created_at']\n",
      "\n",
      "\n",
      "[['12224879', 'Interactive Dynamic Video', 'http://www.interactivedynamicvideo.com/', '386', '52', 'ne0phyte', '8/4/2016 11:52'], ['10975351', 'How to Use Open Source and Shut the Fuck Up at the Same Time', 'http://hueniverse.com/2016/01/26/how-to-use-open-source-and-shut-the-fuck-up-at-the-same-time/', '39', '10', 'josep2', '1/26/2016 19:30'], ['11964716', \"Florida DJs May Face Felony for April Fools' Water Joke\", 'http://www.thewire.com/entertainment/2013/04/florida-djs-april-fools-water-joke/63798/', '2', '1', 'vezycash', '6/23/2016 22:20'], ['11919867', 'Technology ventures: From Idea to Enterprise', 'https://www.amazon.com/Technology-Ventures-Enterprise-Thomas-Byers/dp/0073523429', '3', '1', 'hswarna', '6/17/2016 0:01'], ['10301696', 'Note by Note: The Making of Steinway L1037 (2007)', 'http://www.nytimes.com/2007/11/07/movies/07stein.html?_r=0', '8', '2', 'walterbell', '9/30/2015 4:12']]\n"
     ]
    }
   ],
   "source": [
    "headers = hn[0]\n",
    "hn = hn[1:]\n",
    "print(headers)\n",
    "print(\"\\n\")\n",
    "print(hn[0:5])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extract *Ask HN* and *Show HN* Posts ###"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since we're only concerned with post titles beginning with or , we'll create new lists of lists containing just the data for those titles. hnAsk HNShow HN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The number of Ask HN post 1744\n",
      "The number of Show HN post 1162\n",
      "The number of other HN post 17194\n"
     ]
    }
   ],
   "source": [
    "ask_posts = []\n",
    "show_posts = []\n",
    "other_posts = []\n",
    "\n",
    "\n",
    "for row in hn:\n",
    "    title = row[1].lower()\n",
    "    if title.startswith('ask hn'):\n",
    "        ask_posts.append(row)\n",
    "    elif title.startswith('show hn'):\n",
    "        show_posts.append(row)\n",
    "    else:\n",
    "        other_posts.append(row)\n",
    "\n",
    "print('The number of Ask HN post {}'.format(len(ask_posts)))\n",
    "print('The number of Show HN post {}'.format(len(show_posts)))\n",
    "print('The number of other HN post {}'.format(len(other_posts)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ask HN: How to improve my personal website?\n",
      "Ask HN: Why are papers still published as PDFs?\n",
      "Ask HN: Am I the only one outraged by Twitter shutting down share counts?\n",
      "Ask HN: How do you balance a serious relationship with starting a company?\n",
      "\n",
      "\n",
      "Show HN: Wio Link  ESP8266 Based Web of Things Hardware Development Platform\n",
      "Show HN: Parse recipe ingredients using JavaScript\n",
      "Show HN: Something pointless I made\n",
      "Show HN: PhantomJsCloud, Headless Browser SaaS\n"
     ]
    }
   ],
   "source": [
    "for entry in range(0,2):\n",
    "    print(ask_posts[entry][1])\n",
    "    print(ask_posts[-entry-1][1])\n",
    "\n",
    "print(\"\\n\")\n",
    "\n",
    "for entry in range(0, 2):\n",
    "    print(show_posts[entry][1])\n",
    "    print(show_posts[-entry-1][1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's move on to answering the first basic question, whether **ask posts** or **show posts** gets more comments on average.\n",
    "\n",
    "To check this, we have to find the number of comments in each post at index 4, add this value to a total_comments variable and divide it by the length of each list."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Extract the average comments of Show HN& Ask HN comments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6\n",
      "29\n",
      "1\n"
     ]
    }
   ],
   "source": [
    "for row in ask_posts[0:3]:\n",
    "    print(row[4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The averager number of comments on ask posts is 14.04 \n",
      "The averager number of comments on ask posts is 10.32 \n"
     ]
    }
   ],
   "source": [
    "# ask nh\n",
    "total_ask_comments = 0\n",
    "for row in ask_posts:\n",
    "    num_comments = int(row[4])\n",
    "    total_ask_comments+=num_comments\n",
    "\n",
    "avg_ask_comments = total_ask_comments/len(ask_posts)\n",
    "\n",
    "# show nh average and total number\n",
    "total_show_comments = 0\n",
    "for row in show_posts:\n",
    "    num_comments = int(row[4])\n",
    "    total_show_comments+=num_comments\n",
    "\n",
    "avg_show_comments = total_show_comments/len(show_posts)\n",
    "\n",
    "print(\"The averager number of comments on ask posts is {:,.2f} \".format(avg_ask_comments))\n",
    "print(\"The averager number of comments on ask posts is {:,.2f} \".format(avg_show_comments))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To get a conclusion, I decide to subtract the calculated average number of ask posts froem the calculted average number of show posts and get the average number of comments which we receive more per post"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The ask section gets 3.72 more comments\n"
     ]
    }
   ],
   "source": [
    "avg_comments = avg_ask_comments - avg_show_comments\n",
    "print(\"The ask section gets \"+\"{:.2f}\".format(avg_comments)+' more comments')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** Asl posts ** receiver on average about ***4 comments* more per post \n",
    "\n",
    "This is esay to explanined , for example , by the fact that in the Ask-section ,user are asked in particular fot soulation approcahes and are therefore moe invovloed than in Show-section.\n",
    "\n",
    "Since asks posts are more likely to receive the comments , we will foucus our remaining analusisi just on these pots\n",
    "\n",
    "As a next step, we will inverstigate whethere posts created ar a certain time receive more comments. For this we will calculate the number of asl posts created in each hour of dat, along with the number of comments receiveed and calculate the acerage number of comments ask poys reciive by hour."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime as dt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "result_list = []\n",
    "\n",
    "# we iterate trough each post in ask_post, then asign\n",
    "# the timestamp to created_at and the number of comments\n",
    "# to num_comments. At the end we append a list with that\n",
    "# data to the result_list\n",
    "\n",
    "\n",
    "for row in ask_posts:\n",
    "    created_at = row[6]\n",
    "    num_comment = row[4]\n",
    "    list = [created_at,num_comment]\n",
    "    result_list.append(list)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['8/16/2016 9:55', '6'],\n",
       " ['11/22/2015 13:43', '29'],\n",
       " ['5/2/2016 10:14', '1'],\n",
       " ['8/2/2016 14:20', '3'],\n",
       " ['10/15/2015 16:38', '17']]"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result_list[0:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "counts_by_hour = {} # contains the number of ask posts created during each hour of the day\n",
    "comments_by_hour = {}\n",
    "for row in result_list:\n",
    "    num_comment = int(row[1])\n",
    "    hour_dt = dt.datetime.strptime(row[0],\"%m/%d/%Y %H:%M\") # we convert the date string to a datetime object\n",
    "    hour = hour_dt.strftime('%H')# we ectract the hour (%H) from the datetime object\n",
    "\n",
    "\n",
    "    # now we create a frequent table and count the hour to get\n",
    "    # the number of posts for each hour and set the comments by hour\n",
    "    # equal to the comment number to get the comments in each hour.\n",
    "    if hour in counts_by_hour:\n",
    "        counts_by_hour[hour]+=1\n",
    "        comments_by_hour[hour]+= num_comment\n",
    "    else:\n",
    "        counts_by_hour[hour]=1\n",
    "        comments_by_hour[hour]= num_comment\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "hours = []\n",
    "for hour in counts_by_hour:\n",
    "    avg_by_hours = comments_by_hour[hour]/counts_by_hour[hour]\n",
    "    hours.append([hour,avg_by_hours])\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['09', 5.5777777777777775],\n",
       " ['13', 14.741176470588234],\n",
       " ['10', 13.440677966101696],\n",
       " ['14', 13.233644859813085],\n",
       " ['16', 16.796296296296298],\n",
       " ['23', 7.985294117647059],\n",
       " ['12', 9.41095890410959],\n",
       " ['17', 11.46],\n",
       " ['15', 38.5948275862069],\n",
       " ['21', 16.009174311926607],\n",
       " ['20', 21.525],\n",
       " ['02', 23.810344827586206],\n",
       " ['18', 13.20183486238532],\n",
       " ['03', 7.796296296296297],\n",
       " ['05', 10.08695652173913],\n",
       " ['19', 10.8],\n",
       " ['01', 11.383333333333333],\n",
       " ['22', 6.746478873239437],\n",
       " ['08', 10.25],\n",
       " ['04', 7.170212765957447],\n",
       " ['00', 8.127272727272727],\n",
       " ['06', 9.022727272727273],\n",
       " ['07', 7.852941176470588],\n",
       " ['11', 11.051724137931034]]"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hours"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[5.5777777777777775, '09'], [14.741176470588234, '13'], [13.440677966101696, '10'], [13.233644859813085, '14'], [16.796296296296298, '16'], [7.985294117647059, '23'], [9.41095890410959, '12'], [11.46, '17'], [38.5948275862069, '15'], [16.009174311926607, '21'], [21.525, '20'], [23.810344827586206, '02'], [13.20183486238532, '18'], [7.796296296296297, '03'], [10.08695652173913, '05'], [10.8, '19'], [11.383333333333333, '01'], [6.746478873239437, '22'], [10.25, '08'], [7.170212765957447, '04'], [8.127272727272727, '00'], [9.022727272727273, '06'], [7.852941176470588, '07'], [11.051724137931034, '11']]\n"
     ]
    }
   ],
   "source": [
    "avg_by_hour = hours\n",
    "swap_avg_by_hour= []\n",
    "for row in avg_by_hour:\n",
    "    swap_avg_by_hour.append([row[1],row[0]])\n",
    "print(swap_avg_by_hour)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "swap_avg_by_hour = sorted(swap_avg_by_hour,reverse=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[38.5948275862069, '15'],\n",
       " [23.810344827586206, '02'],\n",
       " [21.525, '20'],\n",
       " [16.796296296296298, '16'],\n",
       " [16.009174311926607, '21']]"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "swap_avg_by_hour[0:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15:00: 38.59 comments per post\n",
      "02:00: 23.81 comments per post\n",
      "20:00: 21.52 comments per post\n",
      "16:00: 16.80 comments per post\n",
      "21:00: 16.01 comments per post\n"
     ]
    }
   ],
   "source": [
    "for average, hour in swap_avg_by_hour[:5]:\n",
    "    hour_object = dt.datetime.strptime(hour, '%H') # convert the string to datetime object\n",
    "    time = hour_object.strftime('%H:%M') # format the datetime object \n",
    "    print('{time}: {average:.2f} comments per post'.format(time=time, average=average) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15:00:38.59 commonts per post\n",
      "02:00:23.81 commonts per post\n",
      "20:00:21.52 commonts per post\n",
      "16:00:16.80 commonts per post\n",
      "21:00:16.01 commonts per post\n"
     ]
    }
   ],
   "source": [
    "for average,hours in swap_avg_by_hour[0:5]:\n",
    "    hour_object = dt.datetime.strptime(hours, '%H')\n",
    "    hour = hour_object.strftime(\"%H:%M\")\n",
    "    print('{time}:{average:.2f} commonts per post'.format(time = hour,average = average))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We should create a post at 15:00 o'clock to have a higher chance of reveiving comments. \n",
    "\n",
    "This dataset refers to the time zone in eastern time, so because I live in London, we need to add 7 hours to each time to get the right time to post in germany on the website of Hacker News."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top 5 Hours in CET (Berlin) for Ask Posts Comments\n",
      "21:00: 38.59 comments per post\n",
      "08:00: 23.81 comments per post\n",
      "02:00: 21.52 comments per post\n",
      "22:00: 16.80 comments per post\n",
      "03:00: 16.01 comments per post\n"
     ]
    }
   ],
   "source": [
    "print('Top 5 Hours in CET (Berlin) for Ask Posts Comments')\n",
    "\n",
    "for average, hour in swap_avg_by_hour[:5]:\n",
    "    hour_object = dt.datetime.strptime(hour, '%H') # convert the string to datetime object\n",
    "    cet = hour_object + dt.timedelta(hours=6)\n",
    "    time = cet.strftime('%H:%M') # format the datetime object\n",
    "    print('{time}: {average:.2f} comments per post'.format(time=time, average=average))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In our analysis we found out that there are the most comments in the Ask-Section. In order for our articles to have a higher chance of receiving as many comments as possible, we should publish an article around **3pm**. Since I'm located in London, we stick to the UTM and should therefore publish an article around **9pm**.\n",
    "\n",
    "Even though this analysis has now given us an estimate of when it is worth writing an article, it doesn't mean that we will always get the most comments if we publish at 3pm. So, of course, the content of the article still plays a key role."
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "e539f2aed5b8c1dec2f462066edd40c3c00b3652e0121e5111b6431838094bf5"
  },
  "kernelspec": {
   "display_name": "Python 3.8.5 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
